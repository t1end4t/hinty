# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\nclient<llm> GeminiRouter {\n  provider \"openai-generic\"\n  retry_policy Exponential\n  options {\n    base_url \"https://openrouter.ai/api/v1\"\n    api_key env.GOOGLE_API_KEY\n    model \"gemini-flash-latest\"\n  }\n}\n\nclient<llm> GroqRouter {\n  provider openai-generic\n  retry_policy Exponential\n  options {\n    base_url \"https://api.groq.com/openai/v1\"\n    api_key env.GROQ_API_KEY\n    model \"openai/gpt-oss-120b\"\n  }\n}\n\nclient<llm> GrokCoder {\n  provider \"openai-generic\"\n  retry_policy Exponential\n  options {\n    base_url \"https://openrouter.ai/api/v1\"\n    api_key env.OPENROUTER_API_KEY\n    model \"x-ai/grok-code-fast-1\"\n  }\n}\n\nclient<llm> ClaudeWriter {\n  provider \"openai-generic\"\n  retry_policy Exponential\n  options {\n    base_url \"https://openrouter.ai/api/v1\"\n    api_key env.OPENROUTER_API_KEY\n    model \"anthropic/claude-sonnet-4.5\"\n  }\n}\n\nclient<llm> Thinking {\n  provider \"openai-generic\"\n  retry_policy Exponential\n  options {\n    base_url \"https://openrouter.ai/api/v1\"\n    api_key env.OPENROUTER_API_KEY\n    model \"anthropic/claude-opus-4.1\"\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "coder.baml": "class CoderOutput {\n  diff_content string\n  response string\n}\n  \nclass FileInfo {\n  file_path string\n  file_content string\n}\n\nfunction Coder(\n  user_message: string,\n  files: FileInfo[],\n  conversation_history: ConversationMessage[]\n) -> CoderOutput {\n  client GroqRouter\n  prompt #\"\nYou are an expert code editor assistant. Your task is to analyze the provided code files and generate precise search/replace blocks to implement the user's requested changes.\n\n## Input Context\n\n### Files to Modify\n{% for file in files %}\nFile: {{ file.file_path }}\n```\n{{ file.file_content }}\n```\n\n{% endfor %}\n\n{% if conversation_history|length > 0 %}\n### Previous Conversation\n{% for msg in conversation_history %}\n{{ msg.role }}: {{ msg.content }}\n{% endfor %}\n\n{% endif %}\n\n### User Request\n{{ user_message }}\n\n## Your Task\n\nGenerate search/replace blocks that implement the requested changes. Follow this exact format for each change:\n\n```\nfile_path\n```language\n<<<<<<< SEARCH\n[exact code to find - must match precisely including whitespace]\n=======\n[replacement code with the same indentation]\n>>>>>>> REPLACE\n```\n```\n\n## Requirements\n\n1. **Precision**: SEARCH blocks must match the original code exactly (including whitespace and indentation)\n2. **Minimal changes**: Only modify what's necessary to address the request\n3. **Style preservation**: Maintain existing code style, formatting, and conventions\n4. **Multiple changes**: Create separate search/replace blocks for each distinct change\n5. **Explanation**: After the blocks, provide a clear summary of what changed and why\n\n## Response Structure\n\nFirst, output all search/replace blocks, then provide your explanation.\n\n{{ ctx.output_format }}\n  \"#\n}\n\n\ntest CoderSimpleChange {\n  functions [Coder]\n  args {\n    user_message \"Change the greeting to say 'Hi there!'\"\n    files [\n      {\n        file_path \"example.py\"\n        file_content #\"\ndef hello():\n    print(\"Hello, World!\")\n\"#\n      }\n    ]\n    conversation_history []\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.213.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "router.baml": "class ConversationMessage {\n  role \"user\" | \"assistant\"\n  content string\n}\n\nfunction Router(message: string, conversation_history: ConversationMessage[]?) -> string {\n  client GroqRouter\n  prompt #\"\n    You are a helpful assistant.\n\n    {% if conversation_history %}\n    CONVERSATION HISTORY:\n    {% for msg in conversation_history -%}\n    {{ msg.role | capitalize }}: {{ msg.content }}\n    {% endfor %}\n    {% endif %}\n\n    Current Question: {{ message }}\n\n    Your helpful response:\n  \"#\n}\n\ntest TestRouter1{\n    functions [Router]\n    args {\n        message \"Do you remember my name?\"\n        conversation_history [\n            {role: \"user\", content: \"Hi, I am Dat\"}\n            {role: \"assistant\", content: \"Hi Dat\"}\n        ]\n    }\n}\n\ntest TestRouter2{\n    functions [Router]\n    args {\n        message \"What is the capital of France?\"\n    }\n}\n",
}

def get_baml_files():
    return _file_map